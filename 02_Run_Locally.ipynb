{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Local Run\n",
    "In this notebook, we create an Azure ML workspace, and use it to locally run the training script.\n",
    "\n",
    "The steps in this notebook are\n",
    "- [import libraries](#import),\n",
    "- [set the Azure subscription](#subscription),\n",
    "- [create an Azure ML workspace](#workspace),\n",
    "- [create an estimator](#estimator),\n",
    "- [create an experiment](#experiment),\n",
    "- [submit the estimator](#submit), and\n",
    "- [get the results](#results).\n",
    "\n",
    "## Imports  <a id='import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from azure.common.credentials import get_cli_profile\n",
    "from azureml.core import Workspace, Experiment, ScriptRunConfig\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.estimator import Estimator\n",
    "import azureml.core\n",
    "print('azureml.core.VERSION={}'.format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure subscription <a id='subscription'></a>\n",
    "If you have multiple subscriptions select the subscription you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "%env selected_subscription=Boston Team Danielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Azure if not already logged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ] || [ \"$list\" == '' ]; then \n",
    "  az login -o table\n",
    "else\n",
    "  az account list -o table \n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the selected subscription as the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az account set --subscription \"$selected_subscription\"\n",
    "az account show -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information for the selected Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_profile = get_cli_profile()\n",
    "subscription_id = az_profile.get_subscription_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML workspace <a id='workspace'></a>\n",
    "Create a workspace, if it does not already exist, and write it out to `config.json` to reference it between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ws = Workspace.create(name='mabouhype',\n",
    "                      subscription_id=subscription_id,\n",
    "                      resource_group='maboutest',\n",
    "                      create_resource_group=True,\n",
    "                      exist_ok=True,\n",
    "                      location='eastus')\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator <a id='estimator'></a>\n",
    "Create an estimator that specifies the location of the script, sets up its parameters, including the location of the data which it mounts to the Docker container, and specifies the packages needed to run the script. It may take a while to prepare the run environment the first time an estimator is used, but that environment will be used until the list of packages is changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(source_directory=os.path.join('.', 'scripts'), \n",
    "                entry_script='TrainTestClassifier.py',\n",
    "                script_params={'--data-folder': '/data',\n",
    "                               '--estimators': '1000',\n",
    "                               '--match': '5',\n",
    "                               '--ngrams': '2',\n",
    "                               '--min_child_samples': '10'},\n",
    "                compute_target='local',\n",
    "                conda_packages=['pandas==0.23.4',\n",
    "                                'scikit-learn==0.20.0'],\n",
    "                pip_packages=['lightgbm==2.1.2'])\n",
    "# Indicate the mount point of the data in the Docker container.\n",
    "est.run_config.environment.docker.arguments.extend(['-v', ''.join([os.path.abspath('.'), ':', '/data'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment <a id='experiment'></a>\n",
    "Get an experiment to run the script; create it if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='mabouhypelocal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the script <a id='submit'></a>\n",
    "Submit the estimator containing the script to be run. This should return almost immediately, and the value is an object that lets you programmatically control the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run = exp.submit(est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment returns a table with a link to the `Details Page` in the Azure Portal. That page will let you monitor the status of this run of the experiment, and that of previous runs of that experiment. By clicking on a particular run, you can see its details, files output by the script, and the logs of the run, including the `driver.log` with the script's print outs.\n",
    "\n",
    "## Get the results <a id='results'></a>\n",
    "Wait for the run to complete. This returns a `dict` with detailed information about the run. Here, we see that the run is either `Finalizing` or has `Completed`. Other statuses include `Queued`, `Preparing`, `Initializing`, `Running`, and `Failed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_status = run.wait_for_completion()\n",
    "run_status['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the metrics logged by the script during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [the next notebook](03_Hyperparameter_Search.ipynb), we use the AML SDK to tune the set of hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLBatchAIHyperparameterTuning]",
   "language": "python",
   "name": "conda-env-MLBatchAIHyperparameterTuning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
