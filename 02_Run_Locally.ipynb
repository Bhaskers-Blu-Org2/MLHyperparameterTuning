{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Local Run\n",
    "In this notebook, we create an Azure ML workspace, and use it to locally run the training script.\n",
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from azureml.core import Workspace, Experiment, ScriptRunConfig\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import azureml.core\n",
    "print('azureml.core.VERSION={}'.format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure subscription\n",
    "If you have multiple subscriptions select the subscription you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "%env selected_subscription=Boston Team Danielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Azure if not already logged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ] || [ \"$list\" == '' ]; then \n",
    "  az login -o table\n",
    "else\n",
    "  az account list -o table \n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the selected subscription as the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az account set --subscription \"$selected_subscription\"\n",
    "az account show -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information for the selected Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_json = !az account show\n",
    "account = json.loads(''.join(account_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML workspace\n",
    "Create a workspace, if it does not already exist, and write it out to `config.json` to reference it between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ws = Workspace.create(name='maboutest',\n",
    "                      subscription_id=account['id'],\n",
    "                      resource_group='maboutest',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2',\n",
    "                      exist_ok=True)\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the run configuration\n",
    "Define a system-managed run configuration. This configuration is used to create the environment in which the script will be run. It may take a while to build the environment the first time a run configuration is used, but that environment will be used until the run configuration is changed.  Note that `azureml-sdk` is included in the `pip_packages` because it is used by our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "run_config.auto_prepare_environment = True\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas==0.23.4',\n",
    "                    'scikit-learn==0.20.0'],\n",
    "    pip_packages=['azureml-sdk',\n",
    "                  'lightgbm==2.1.2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the script configuration\n",
    "Specify the script to be run on your local machine. The path to the `data` directory must be absolute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ScriptRunConfig(source_directory=os.path.join('.', 'scripts'), \n",
    "                      script='TrainTestClassifier.py', \n",
    "                      arguments=['--inputs', os.path.abspath('data'),\n",
    "                                 '--estimators', '1000',\n",
    "                                 '--match', '5',\n",
    "                                 '--ngrams', '2',\n",
    "                                 '--min_child_samples', '10'],\n",
    "                      run_config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment\n",
    "Get an experiment to run the script; create it if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='mabouhypelocal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script\n",
    "Submit the script to be run. This should return almost immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.submit(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment returns a table with a link to the `Details Page` in the Azure Portal. That page will let you monitor the status of this run of the experiment, and that of previous runs of that experiment. By clicking on a particular run, you can see its details, files output by the script, and the logs of the run, including the `driver.log` with the script's print outs.\n",
    "\n",
    "Get an object associated with the latest run. Using this object, you can programmatically control the job. This object was the value returned by the `exp.submit(src)` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_local = list(exp.get_runs())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the run to complete. This returns a `dict` with detailed information about the run. Here, we see that the run is either `Finalizing` or has `Completed`. Other states include `Running` and `Failed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_status = run_local.wait_for_completion()\n",
    "run_status['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the metrics logged by the script during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLBatchAIHyperparameterTuning]",
   "language": "python",
   "name": "conda-env-MLBatchAIHyperparameterTuning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
