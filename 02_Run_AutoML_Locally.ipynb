{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Local Run\n",
    "In this notebook, we create an Azure ML workspace, and use it to locally run the training script.\n",
    "\n",
    "The steps in this notebook are\n",
    "- [import libraries](#import),\n",
    "- [set the Azure subscription](#subscription),\n",
    "- [create an Azure ML workspace](#workspace),\n",
    "- [create an estimator](#estimator),\n",
    "- [create an experiment](#experiment),\n",
    "- [submit the estimator](#submit), and\n",
    "- [get the results](#results).\n",
    "\n",
    "## Imports  <a id='import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow module is not present, models based on tensorflow would not work\n",
      "azureml.core.VERSION=1.0.21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from azure.common.credentials import get_cli_profile\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import azureml.core\n",
    "from get_auth import get_auth\n",
    "print('azureml.core.VERSION={}'.format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure subscription <a id='subscription'></a>\n",
    "If you have multiple subscriptions select the subscription you want to use. You can also set the name of the resource group in which this tutorial will add resources. *IMPORTANT NOTE:* The last notebook in this example will delete this resource group and all associated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "selected_subscription=\"AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734\"\n",
    "resource_group=\"hypetuning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Azure if not already logged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                               CloudName    SubscriptionId                        State    IsDefault\n",
      "-------------------------------------------------  -----------  ------------------------------------  -------  -----------\n",
      "AG-AzureCAT-AIDanC-Test-COGSNonProd-IO1685734      AzureCloud   3bcfa59c-82a0-44f9-ac08-b3479370bace  Enabled  False\n",
      "DEMO - how RepDemo are you                         AzureCloud   fe4d94f0-dc5b-4c09-9b85-863413b0192b  Enabled  False\n",
      "Edge-ES-CI-Manual                                  AzureCloud   333e402a-65a0-45a9-8e23-867ca146c290  Enabled  False\n",
      "Cosmos_WDG_Core_BnB_100348                         AzureCloud   dae41bd3-9db4-4b9b-943e-832b57cac828  Enabled  False\n",
      "Azure Stack Diagnostics CI and Production VaaS     AzureCloud   a8183b2d-7a4c-45e9-8736-dac11b84ff14  Enabled  False\n",
      "Data Wrangling Preview                             AzureCloud   215613ac-9dfb-488c-be46-c387e999b127  Enabled  False\n",
      "CAT_Eng                                            AzureCloud   eb87f285-893a-4f0f-8c55-7b4f67b1d097  Enabled  False\n",
      "Core-ES-WM-Ext                                     AzureCloud   52a442a2-31e9-42f9-8e3e-4b27dbf82673  Enabled  False\n",
      "Boston-DS-Brandon-Dev                              AzureCloud   e984a9db-1a27-4f54-98fc-282cf0dcda04  Enabled  False\n",
      "AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734  AzureCloud   edf507a2-6235-46c5-b560-fd463ba2e771  Enabled  True\n",
      "AG-AzureCAT-AIAbhinav-Test-COGSNonProd-IO1685734   AzureCloud   bc4170f0-cc6e-49d2-ba65-bc00a7a4df6b  Enabled  False\n",
      "Azure Internal - TATK                              AzureCloud   872ff0da-188e-4461-8cf7-26e1c3e28ebb  Enabled  False\n",
      "Enterprise Dev/Test                                AzureCloud   9bb48a85-ce2f-4884-bbe5-0dc2d6c00703  Enabled  False\n",
      "AG-AzureCAT-AIDevOps-Test-COGSNonProd-IO1685734    AzureCloud   0ca618d2-22a8-413a-96d0-0f1b531129c3  Enabled  False\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ] || [ \"$list\" == '' ]; then \n",
    "  az login -o table\n",
    "else\n",
    "  az account list -o table \n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the selected subscription as the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvironmentName    IsDefault    Name                                               State    TenantId\n",
      "-----------------  -----------  -------------------------------------------------  -------  ------------------------------------\n",
      "AzureCloud         True         AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$selected_subscription\"\n",
    "az account set --subscription \"$1\"\n",
    "az account show -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information for the selected Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_profile = get_cli_profile()\n",
    "subscription_id = az_profile.get_subscription_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML workspace <a id='workspace'></a>\n",
    "Create a workspace if it does not already exist or recover it if it does exist, and write out its details to `config.json` to reference it between notebooks. THe first time this is run, this can take about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create Workspace with CLI Authentication\n",
      "Wrote the config file config.json to: /data/home/mabou/Source/Repos/MLHyperparameterTuning/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "auth = get_auth()\n",
    "ws = Workspace.create(name='hypetuning',\n",
    "                      subscription_id=subscription_id,\n",
    "                      resource_group=resource_group,\n",
    "                      create_resource_group=True,\n",
    "                      exist_ok=True,\n",
    "                      location='eastus',\n",
    "                      auth=auth)\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "train_path = os.path.join(data_path, \"balanced_pairs_train.tsv\")\n",
    "tune_path = os.path.join(data_path, \"balanced_pairs_tune.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', encoding='latin1')\n",
    "tune = pd.read_csv(tune_path, sep='\\t', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"Text_x\", \"Text_y\"]\n",
    "label_column = \"Label\"\n",
    "group_column = 'Id_x'\n",
    "answerid_column = 'AnswerId_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train.Text_x + ' ' + train.Text_y).values  # train_X = train[feature_columns]\n",
    "train_y = train[label_column].values\n",
    "tune_X = (tune.Text_x + ' ' + tune.Text_y).values  # tune_X = tune[feature_columns]\n",
    "tune_y = tune[label_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.51\n",
      "1   20.00\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = train[label_column].value_counts()\n",
    "train_label_weight = train.shape[0] / (train_label_counts.shape[0] * train_label_counts)\n",
    "print(train_label_weight)\n",
    "train_weight = train[label_column].apply(lambda x: train_label_weight[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.50\n",
      "1   91.00\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tune_label_counts = tune[label_column].value_counts()\n",
    "tune_label_weight = tune.shape[0] / (tune_label_counts.shape[0] * tune_label_counts)\n",
    "print(tune_label_weight)\n",
    "tune_weight = tune[label_column].apply(lambda x: tune_label_weight[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_ml_config = AutoMLConfig(task=\"classification\",\n",
    "                                   primary_metric=\"accuracy\",\n",
    "                                   X=train_X,\n",
    "                                   y=train_y,\n",
    "                                   sample_weight=train_weight,\n",
    "                                   X_valid=tune_X,\n",
    "                                   y_valid=tune_y,\n",
    "                                   sample_weight_valid=tune_weight,\n",
    "                                   preprocess=True,\n",
    "                                   iterations=30,\n",
    "                                   iteration_timeout_minutes=15,\n",
    "                                   blacklist_models=[\"LightGBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='hypetuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_6640c010-3387-4494-b79c-8de76dea44a3\n",
      "********************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "SAMPLING %: Percent of the training data to sample.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler ExtremeRandomTrees                100.0000    0:05:45       0.5000    0.5000\n",
      "         1   MaxAbsScaler SGD                               100.0000    0:04:10       0.6945    0.6945\n",
      "         2   MaxAbsScaler RandomForest                      100.0000    0:03:36       0.5873    0.6945\n",
      "         3   StandardScalerWrapper ExtremeRandomTrees       100.0000    0:07:44       0.7382    0.7382\n",
      "         4   MaxAbsScaler RandomForest                      100.0000    0:05:55       0.5000    0.7382\n",
      "         5   MaxAbsScaler SGD                               100.0000    0:03:48       0.7044    0.7382\n",
      "         6   MaxAbsScaler SGD                               100.0000    0:02:44       0.5422    0.7382\n",
      "         7   StandardScalerWrapper RandomForest             100.0000    0:03:10       0.5000    0.7382\n",
      "         8   SparseNormalizer ExtremeRandomTrees            100.0000    0:05:50       0.5000    0.7382\n",
      "         9   MaxAbsScaler SGD                               100.0000    0:03:13       0.5000    0.7382\n",
      "        10   MaxAbsScaler LogisticRegression                100.0000    0:06:24       0.7886    0.7886\n",
      "        11   TruncatedSVDWrapper LogisticRegression         100.0000    0:11:40       0.5016    0.7886\n",
      "        12                                                  100.0000    0:16:22          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        13   StandardScalerWrapper LogisticRegression       100.0000    0:09:11       0.5119    0.7886\n",
      "        14   MaxAbsScaler RandomForest                      100.0000    0:04:47       0.5000    0.7886\n",
      "        15                                                  100.0000    0:16:19          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        16   StandardScalerWrapper RandomForest             100.0000    0:02:09       0.5000    0.7886\n",
      "        17                                                  100.0000    0:16:14          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        18                                                  100.0000    0:16:15          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        19                                                  100.0000    0:16:18          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        20   MaxAbsScaler LogisticRegression                100.0000    0:04:35       0.6295    0.7886\n",
      "        21                                                  100.0000    0:16:15          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        22                                                  100.0000    0:16:15          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        23   MaxAbsScaler SGD                               100.0000    0:02:22       0.7563    0.7886\n",
      "        24   MaxAbsScaler RandomForest                      100.0000    0:05:16       0.7014    0.7886\n",
      "        25   StandardScalerWrapper LogisticRegression       100.0000    0:04:00       0.6302    0.7886\n",
      "        26                                                  100.0000    0:16:19          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        27                                                  100.0000    0:16:14          nan    0.7886\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration.\n",
      "        28   StandardScalerWrapper LogisticRegression       100.0000    0:05:54       0.7422    0.7886\n",
      "        29   Ensemble                                       100.0000    0:07:59       0.8016    0.8016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>hypetuning</td><td>AutoML_6640c010-3387-4494-b79c-8de76dea44a3</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/hypetuning/providers/Microsoft.MachineLearningServices/workspaces/hypetuning/experiments/hypetuning/runs/AutoML_6640c010-3387-4494-b79c-8de76dea44a3\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: hypetuning,\n",
       "Id: AutoML_6640c010-3387-4494-b79c-8de76dea44a3,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_run = exp.submit(automated_ml_config, show_output=True)\n",
    "local_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = local_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>hypetuning</td><td>AutoML_6640c010-3387-4494-b79c-8de76dea44a3_29</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/hypetuning/providers/Microsoft.MachineLearningServices/workspaces/hypetuning/experiments/hypetuning/runs/AutoML_6640c010-3387-4494-b79c-8de76dea44a3_29\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: hypetuning,\n",
       "Id: AutoML_6640c010-3387-4494-b79c-8de76dea44a3_29,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('datatransformer', DataTransformer(is_onnx_compatible=None, logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
       "               estimators=[('ExtremeRandomTrees_8', Pipeline(memory=None,\n",
       "     steps=[('sparsenormalizer', <automl...6666667, 0.13333333333333333, 0.06666666666666667, 0.26666666666666666, 0.06666666666666667, 0.2]))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = best_run[1]\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('datatransformer',\n",
       "   DataTransformer(is_onnx_compatible=None, logger=None, task=None)),\n",
       "  ('MaxAbsScaler', MaxAbsScaler(copy=True)),\n",
       "  ('SGDClassifierWrapper',\n",
       "   SGDClassifierWrapper(alpha=4.693930612244897, class_weight=None, eta0=0.01,\n",
       "              fit_intercept=True, l1_ratio=0.6326530612244897,\n",
       "              learning_rate='constant', loss='modified_huber', max_iter=1000,\n",
       "              n_jobs=1, penalty='none', power_t=0, random_state=None,\n",
       "              tol=0.01))],\n",
       " 'datatransformer': DataTransformer(is_onnx_compatible=None, logger=None, task=None),\n",
       " 'MaxAbsScaler': MaxAbsScaler(copy=True),\n",
       " 'SGDClassifierWrapper': SGDClassifierWrapper(alpha=4.693930612244897, class_weight=None, eta0=0.01,\n",
       "            fit_intercept=True, l1_ratio=0.6326530612244897,\n",
       "            learning_rate='constant', loss='modified_huber', max_iter=1000,\n",
       "            n_jobs=1, penalty='none', power_t=0, random_state=None,\n",
       "            tol=0.01),\n",
       " 'datatransformer__is_onnx_compatible': None,\n",
       " 'datatransformer__logger': None,\n",
       " 'datatransformer__task': None,\n",
       " 'MaxAbsScaler__copy': True,\n",
       " 'SGDClassifierWrapper__alpha': 4.693930612244897,\n",
       " 'SGDClassifierWrapper__class_weight': None,\n",
       " 'SGDClassifierWrapper__eta0': 0.01,\n",
       " 'SGDClassifierWrapper__fit_intercept': True,\n",
       " 'SGDClassifierWrapper__l1_ratio': 0.6326530612244897,\n",
       " 'SGDClassifierWrapper__learning_rate': 'constant',\n",
       " 'SGDClassifierWrapper__loss': 'modified_huber',\n",
       " 'SGDClassifierWrapper__max_iter': 1000,\n",
       " 'SGDClassifierWrapper__penalty': 'none',\n",
       " 'SGDClassifierWrapper__power_t': 0,\n",
       " 'SGDClassifierWrapper__tol': 0.01,\n",
       " 'SGDClassifierWrapper__random_state': None,\n",
       " 'SGDClassifierWrapper__n_jobs': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text_x_HashOneHotEncode_8191',\n",
       " \"Text_y_CharGramCountVec_'innertext' works in ie, but not in firefox. i have some javascript code that works in ie containing the following:  however, it seems that the 'innertext' property does not work in firefox. is there some firefox equivalent? or is there a more generic, cross browser property that can be used?\",\n",
       " 'Text_y_CharGramCountVec_.prop() vs .attr(). so jquery 1.6 has the new function prop().  or in this case do they do the same thing? and if i do have to switch to using prop(), all the old attr() calls will break if i switch to 1.6? update see this fiddle: http://jsfiddle.net/maniator/jpuf2/ the console logs the getattribute as a string, and the attr as a string, but the prop as a cssstyledeclaration, why? and how does that affect my coding in the future?']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.named_steps['datatransformer'].get_engineered_feature_names()[-183:-180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model\n",
    "Read in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(data_path, \"balanced_pairs_test.tsv\")\n",
    "test = pd.read_csv(test_path, sep='\\t', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = (test.Text_x + ' ' + test.Text_y).values  # test[feature_columns]\n",
    "test_y = test[label_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['probabilities'] = best_run[1].predict_proba(test_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the testing data by dupe Id and question AnswerId.\n",
    "test.sort_values([group_column, answerid_column], inplace=True)\n",
    "\n",
    "# Extract the ordered probabilities.\n",
    "probabilities = (\n",
    "    test.probabilities\n",
    "    .groupby(test[group_column], sort=False)\n",
    "    .apply(lambda x: tuple(x.values)))\n",
    "\n",
    "# Get the individual records.\n",
    "output_columns_x = ['Id_x', 'AnswerId_x', 'Text_x']\n",
    "test_score = (test[output_columns_x]\n",
    "              .drop_duplicates()\n",
    "              .set_index(group_column))\n",
    "test_score['probabilities'] = probabilities\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.columns = ['Id', 'AnswerId', 'Text', 'probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score_rank(scores):\n",
    "    \"\"\"Compute the ranks of the scores.\"\"\"\n",
    "    return pd.Series(scores).rank(ascending=False)\n",
    "\n",
    "\n",
    "def label_index(label, label_order):\n",
    "    \"\"\"Compute the index of label in label_order.\"\"\"\n",
    "    loc = np.where(label == label_order)[0]\n",
    "    if loc.shape[0] == 0:\n",
    "        return None\n",
    "    return loc[0]\n",
    "\n",
    "\n",
    "def label_rank(label, scores, label_order):\n",
    "    \"\"\"Compute the rank of label using the scores.\"\"\"\n",
    "    loc = label_index(label, label_order)\n",
    "    if loc is None:\n",
    "        return len(scores) + 1\n",
    "    return score_rank(scores)[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model's performance.\n",
      "Accuracy @1 = 19.19%\n",
      "Accuracy @2 = 28.05%\n",
      "Accuracy @3 = 33.83%\n",
      "Mean Rank 18.2631\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model's performance.\")\n",
    "\n",
    "# Collect the ordered AnswerId for computing scores.\n",
    "labels = sorted(train[answerid_column].unique())\n",
    "label_order = pd.DataFrame({'label': labels})\n",
    "\n",
    "# Compute the ranks of the correct answers.\n",
    "test_score['Ranks'] = test_score.apply(lambda x:\n",
    "                                       label_rank(x.AnswerId,\n",
    "                                                  x.probabilities,\n",
    "                                                  label_order.label),\n",
    "                                       axis=1)\n",
    "\n",
    "# Compute the number of correctly ranked answers\n",
    "args_rank = 3\n",
    "for i in range(1, args_rank+1):\n",
    "    print('Accuracy @{} = {:.2%}'\n",
    "          .format(i, (test_score['Ranks'] <= i).mean()))\n",
    "mean_rank = test_score['Ranks'].mean()\n",
    "print('Mean Rank {:.4f}'.format(mean_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run120_path = os.path.join(\"outputs\", \"AutoML_ef96bf9d-54e7-4c0e-b365-b2f507ef80d9-120.pkl\")\n",
    "run120 = joblib.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
