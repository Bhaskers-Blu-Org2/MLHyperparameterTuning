{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Image\n",
    "We create a docker image to be used to run `TrainTestClassify.py` on the Batch AI cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import shutil\n",
    "import dotenv\n",
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file to contain the name of the docker login and image name to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join('.', '.env')  # The location of the dotenv file\n",
    "if os.path.isfile(dotenv_path):          # Remove any pre-existing dotenv file to ensure a blank slate\n",
    "    os.remove(dotenv_path)\n",
    "with open(dotenv_path, 'w'):             # Create an empty dotenv file\n",
    "    None\n",
    "# Your docker login and image repository name\n",
    "dotenv.set_key(dotenv_path, 'docker_login', 'YOUR_DOCKER_LOGIN')\n",
    "dotenv.set_key(dotenv_path, 'image_repo', '/mlbaiht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join('.', '.env')  # The location of the dotenv file\n",
    "if os.path.isfile(dotenv_path):          # Remove any pre-existing dotenv file to ensure a blank slate\n",
    "    os.remove(dotenv_path)\n",
    "with open(dotenv_path, 'w'):             # Create an empty dotenv file\n",
    "    None\n",
    "# Your docker login and image repository name\n",
    "dotenv.set_key(dotenv_path, 'docker_login', 'mabouatmicrosoft')\n",
    "dotenv.set_key(dotenv_path, 'image_repo', '/mlbaiht')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the contents of the file into the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv -o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Docker directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the directory the conda environment file that specifies the virtual environment for the training script. This includes the Python modules needed to run the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Docker/requirements.txt\n",
    "\n",
    "pandas==0.23.4\n",
    "scikit-learn==0.19.1\n",
    "lightgbm==2.1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the directory the dockerfile specifying the build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Docker/Dockerfile\n",
    "\n",
    "# Start from a Ubuntu image\n",
    "FROM python:3.5.6-stretch\n",
    "\n",
    "# Copy into the image the definition of the requirements.\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Install the requiremnts.\n",
    "RUN python -m pip install -r requirements.txt\n",
    "    \n",
    "# Define the entry point to call Python and list the environment contents.\n",
    "CMD [\"python\", \"-m\", \"pip\", \"freeze\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the docker image. The first time this is run, this could under a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image_name = os.getenv('docker_login') + os.getenv('image_repo')\n",
    "print('Creating Docker image {}'.format(image_name))\n",
    "!docker build -t $image_name Docker --no-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push the image to the docker repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!docker push $image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test our image with our script locally. The `volume` argument maps the local directory that contains our data and script to `/data` in the container. Then, we call Python with a path to the `TrainTestClassifier.py` script, and we pass as an argument to the script the path to the directory that contains the input files.\n",
    "\n",
    "This should take less than two minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!docker run --volume $(pwd):/data $image_name python /data/TrainTestClassifier.py --inputs /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [the next notebook](02_Configure_Batch_AI.ipynb), we create a file to contain the Batch AI configuration we will use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLBatchAIHyperparameterTuning]",
   "language": "python",
   "name": "conda-env-MLBatchAIHyperparameterTuning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
