{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Local Run\n",
    "In this notebook, we create an Azure ML workspace, and use it to locally run the training script.\n",
    "\n",
    "The steps in this notebook are\n",
    "- [import libraries](#import),\n",
    "- [set the Azure subscription](#subscription),\n",
    "- [create an Azure ML workspace](#workspace),\n",
    "- [create an estimator](#estimator),\n",
    "- [create an experiment](#experiment),\n",
    "- [submit the estimator](#submit), and\n",
    "- [get the results](#results).\n",
    "\n",
    "## Imports  <a id='import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core.VERSION=1.0.43\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from azure.common.credentials import get_cli_profile\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import azureml.core\n",
    "from get_auth import get_auth\n",
    "print('azureml.core.VERSION={}'.format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure subscription <a id='subscription'></a>\n",
    "If you have multiple subscriptions select the subscription you want to use. You can also set the name of the resource group in which this tutorial will add resources. *IMPORTANT NOTE:* The last notebook in this example will delete this resource group and all associated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "selected_subscription=\"AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734\"\n",
    "resource_group=\"hypetuningauto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Azure if not already logged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                               CloudName    SubscriptionId                        State    IsDefault\n",
      "-------------------------------------------------  -----------  ------------------------------------  -------  -----------\n",
      "AG-AzureCAT-AIDanC-Test-COGSNonProd-IO1685734      AzureCloud   3bcfa59c-82a0-44f9-ac08-b3479370bace  Enabled  False\n",
      "DEMO - how RepDemo are you                         AzureCloud   fe4d94f0-dc5b-4c09-9b85-863413b0192b  Enabled  False\n",
      "Azure SDK Engineering System                       AzureCloud   a18897a6-7e44-457d-9260-f2854c0aca42  Enabled  False\n",
      "Edge-ES-CI-Manual                                  AzureCloud   333e402a-65a0-45a9-8e23-867ca146c290  Enabled  False\n",
      "Cosmos_WDG_Core_BnB_100348                         AzureCloud   dae41bd3-9db4-4b9b-943e-832b57cac828  Enabled  False\n",
      "Azure Stack Diagnostics CI and Production VaaS     AzureCloud   a8183b2d-7a4c-45e9-8736-dac11b84ff14  Enabled  False\n",
      "WANHealth - Prod                                   AzureCloud   0445d6ee-7566-442a-b6f7-5599d825d90d  Enabled  False\n",
      "CAT_Eng                                            AzureCloud   eb87f285-893a-4f0f-8c55-7b4f67b1d097  Enabled  False\n",
      "Azure_Maps_MDP_Engineering                         AzureCloud   e8b53c88-f8df-42c0-8399-b478bf8df378  Enabled  False\n",
      "Test/Demo - VipSwapper Operations                  AzureCloud   2af266d9-545a-4738-b0dc-28d0b72a2e93  Enabled  False\n",
      "Core-ES-WorkManagement                             AzureCloud   52a442a2-31e9-42f9-8e3e-4b27dbf82673  Enabled  False\n",
      "AI Infra Build                                     AzureCloud   00c06639-6ee4-454e-8058-8d8b1703bd87  Enabled  False\n",
      "Boston-DS-Brandon-Dev                              AzureCloud   e984a9db-1a27-4f54-98fc-282cf0dcda04  Enabled  False\n",
      "AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734  AzureCloud   edf507a2-6235-46c5-b560-fd463ba2e771  Enabled  True\n",
      "AG-AzureCAT-AIDevOps-Test-COGSNonProd-IO1685734    AzureCloud   0ca618d2-22a8-413a-96d0-0f1b531129c3  Enabled  False\n",
      "Azure Internal - TATK                              AzureCloud   872ff0da-188e-4461-8cf7-26e1c3e28ebb  Enabled  False\n",
      "sishq-non-production-sis-ai                        AzureCloud   9bb48a85-ce2f-4884-bbe5-0dc2d6c00703  Enabled  False\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ] || [ \"$list\" == '' ]; then \n",
    "  az login -o table\n",
    "else\n",
    "  az account list -o table \n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the selected subscription as the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvironmentName    IsDefault    Name                                               State    TenantId\n",
      "-----------------  -----------  -------------------------------------------------  -------  ------------------------------------\n",
      "AzureCloud         True         AG-AzureCAT-AIDanielle-Test-COGSNonProd-IO1685734  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$selected_subscription\"\n",
    "az account set --subscription \"$1\"\n",
    "az account show -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information for the selected Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_profile = get_cli_profile()\n",
    "subscription_id = az_profile.get_subscription_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML workspace <a id='workspace'></a>\n",
    "Create a workspace if it does not already exist or recover it if it does exist, and write out its details to `config.json` to reference it between notebooks. THe first time this is run, this can take about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create Workspace with CLI Authentication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=hypetuningauto in location=eastus2 using subscription=edf507a2-6235-46c5-b560-fd463ba2e771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying StorageAccount with name hypetunistorage68e992e86.\n",
      "Deploying AppInsights with name hypetuniinsightsf88241ff.\n",
      "Deployed AppInsights with name hypetuniinsightsf88241ff. Took 8.86 seconds.\n",
      "Deploying KeyVault with name hypetunikeyvaulte3687b31.\n",
      "Deployed KeyVault with name hypetunikeyvaulte3687b31. Took 24.08 seconds.\n",
      "Deploying Workspace with name hypetuning.\n",
      "Deployed StorageAccount with name hypetunistorage68e992e86. Took 42.13 seconds.\n",
      "Deployed Workspace with name hypetuning. Took 35.48 seconds.\n",
      "Deploying Compute Target with name cpu-cluster\n",
      "Deploying Compute Target with name gpu-cluster\n",
      "Deployed Compute Target with name cpu-cluster. Took 15.47 seconds\n",
      "Deployed Compute Target with name gpu-cluster. Took 15.83 seconds\n"
     ]
    }
   ],
   "source": [
    "auth = get_auth()\n",
    "ws = Workspace.create(name='hypetuning',\n",
    "                      subscription_id=subscription_id,\n",
    "                      resource_group=resource_group,\n",
    "                      create_resource_group=True,\n",
    "                      exist_ok=True,\n",
    "                      location='eastus2',\n",
    "                      auth=auth)\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "train_path = os.path.join(data_path, \"balanced_pairs_train.tsv\")\n",
    "tune_path = os.path.join(data_path, \"balanced_pairs_tune.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', encoding='latin1')\n",
    "tune = pd.read_csv(tune_path, sep='\\t', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"Text_x\", \"Text_y\"]\n",
    "label_column = \"Label\"\n",
    "group_column = 'Id_x'\n",
    "answerid_column = 'AnswerId_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train.Text_x + ' ' + train.Text_y).values  # train_X = train[feature_columns]\n",
    "train_y = train[label_column].values\n",
    "tune_X = (tune.Text_x + ' ' + tune.Text_y).values  # tune_X = tune[feature_columns]\n",
    "tune_y = tune[label_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.51\n",
      "1   20.00\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = train[label_column].value_counts()\n",
    "train_label_weight = train.shape[0] / (train_label_counts.shape[0] * train_label_counts)\n",
    "print(train_label_weight)\n",
    "train_weight = train[label_column].apply(lambda x: train_label_weight[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.50\n",
      "1   91.00\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tune_label_counts = tune[label_column].value_counts()\n",
    "tune_label_weight = tune.shape[0] / (tune_label_counts.shape[0] * tune_label_counts)\n",
    "print(tune_label_weight)\n",
    "tune_weight = tune[label_column].apply(lambda x: tune_label_weight[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_ml_config = AutoMLConfig(task=\"classification\",\n",
    "                                   primary_metric=\"AUC_weighted\",\n",
    "                                   X=train_X,\n",
    "                                   y=train_y,\n",
    "                                   sample_weight=train_weight,\n",
    "                                   X_valid=tune_X,\n",
    "                                   y_valid=tune_y,\n",
    "                                   sample_weight_valid=tune_weight,\n",
    "                                   preprocess=True,\n",
    "                                   iterations=50,\n",
    "                                   iteration_timeout_minutes=90,\n",
    "                                   max_concurrent_iterations=16,\n",
    "                                   max_cores_per_iteration=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='hypetuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_9e6cf10c-b107-41d2-a373-e9cf202c9dfa\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:02:24       0.8443    0.8443\n",
      "         1   MaxAbsScaler SGD                               0:01:19       0.6130    0.8443\n",
      "         2   StandardScalerWrapper LightGBM                 0:01:36       0.8498    0.8498\n",
      "         3   MaxAbsScaler RandomForest                      0:01:21       0.7664    0.8498\n",
      "         4   MaxAbsScaler SGD                               0:01:19       0.6720    0.8498\n",
      "         5   MaxAbsScaler ExtremeRandomTrees                0:01:18       0.5060    0.8498\n",
      "         6   MaxAbsScaler SGD                               0:01:19       0.5000    0.8498\n",
      "         7   StandardScalerWrapper ExtremeRandomTrees       0:01:19       0.7439    0.8498\n",
      "         8   MaxAbsScaler RandomForest                      0:01:45       0.7133    0.8498\n",
      "         9   MaxAbsScaler LightGBM                          0:01:45       0.8472    0.8498\n",
      "        10   MaxAbsScaler BernoulliNaiveBayes               0:01:19       0.7942    0.8498\n",
      "        11   MaxAbsScaler SGD                               0:01:19       0.5860    0.8498\n",
      "        12   MaxAbsScaler LightGBM                          0:02:15       0.8781    0.8781\n",
      "        13   MaxAbsScaler ExtremeRandomTrees                0:02:56       0.8235    0.8781\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:01:38       0.8488    0.8781\n",
      "        15   MaxAbsScaler SGD                               0:01:30       0.8622    0.8781\n",
      "        16   MaxAbsScaler LightGBM                          0:01:44       0.8439    0.8781\n",
      "        17   StandardScalerWrapper BernoulliNaiveBayes      0:01:19       0.6928    0.8781\n",
      "        18   MaxAbsScaler RandomForest                      0:03:19       0.5912    0.8781\n",
      "        19   MaxAbsScaler LightGBM                          0:06:22       0.9042    0.9042\n",
      "        20   MaxAbsScaler LightGBM                          0:06:58       0.9232    0.9232\n",
      "        21   StandardScalerWrapper LightGBM                 0:02:38       0.8988    0.9232\n",
      "        22   MaxAbsScaler LightGBM                          0:12:32       0.9561    0.9561\n",
      "        23   MaxAbsScaler LightGBM                          0:10:55       0.9201    0.9561\n",
      "        24   StandardScalerWrapper LightGBM                 0:03:32       0.9337    0.9561\n",
      "        25   MaxAbsScaler LightGBM                          0:01:49       0.8109    0.9561\n",
      "        26   TruncatedSVDWrapper LightGBM                   0:06:55       0.9020    0.9561\n",
      "        27   TruncatedSVDWrapper LightGBM                   0:07:09       0.9321    0.9561\n",
      "        28   TruncatedSVDWrapper LightGBM                   0:07:06       0.8897    0.9561\n",
      "        29   StandardScalerWrapper LightGBM                 0:03:32       0.9223    0.9561\n",
      "        30   TruncatedSVDWrapper LightGBM                   0:06:37       0.8089    0.9561\n",
      "        31   MaxAbsScaler LightGBM                          0:02:46       0.9135    0.9561\n",
      "        32   StandardScalerWrapper LightGBM                 0:02:10       0.8711    0.9561\n",
      "        33   StandardScalerWrapper LightGBM                 0:06:20       0.9285    0.9561\n",
      "        34   MaxAbsScaler LightGBM                          0:04:49       0.9472    0.9561\n",
      "        35   TruncatedSVDWrapper LightGBM                   0:07:08       0.7003    0.9561\n",
      "        36   StandardScalerWrapper LightGBM                 0:10:43       0.9532    0.9561\n",
      "        37   MaxAbsScaler LightGBM                          0:07:11       0.9452    0.9561\n",
      "        38   MaxAbsScaler LightGBM                          0:02:34       0.9018    0.9561\n",
      "        39   MaxAbsScaler LightGBM                          0:06:46       0.8895    0.9561\n",
      "        40   TruncatedSVDWrapper LightGBM                   0:07:14       0.8715    0.9561\n",
      "        41   MaxAbsScaler LightGBM                          0:07:16       0.9396    0.9561\n",
      "        42   MaxAbsScaler LightGBM                          0:04:37       0.9159    0.9561\n",
      "        43   MaxAbsScaler LightGBM                          0:04:09       0.9066    0.9561\n",
      "        44   MaxAbsScaler LightGBM                          0:05:26       0.8796    0.9561\n",
      "        45   TruncatedSVDWrapper LightGBM                   0:07:15       0.7954    0.9561\n",
      "        46   TruncatedSVDWrapper LightGBM                   0:07:44       0.9215    0.9561\n",
      "        47   StandardScalerWrapper LogisticRegression       0:04:53       0.6936    0.9561\n",
      "        48                                                  1:30:21          nan    0.9561\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration. Please consider increasing the iteration_timeout_minutes parameter.\n",
      "        49                                                  1:30:20          nan    0.9561\n",
      "ERROR: Fit operation exceeded provided timeout, terminating and moving onto the next iteration. Please consider increasing the iteration_timeout_minutes parameter.\n",
      "CPU times: user 26min 24s, sys: 5min 31s, total: 31min 56s\n",
      "Wall time: 7h 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "local_run = exp.submit(automated_ml_config, show_output=True)\n",
    "local_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = local_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>hypetuning</td><td>AutoML_9e6cf10c-b107-41d2-a373-e9cf202c9dfa_22</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/hypetuningauto/providers/Microsoft.MachineLearningServices/workspaces/hypetuning/experiments/hypetuning/runs/AutoML_9e6cf10c-b107-41d2-a373-e9cf202c9dfa_22\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: hypetuning,\n",
       "Id: AutoML_9e6cf10c-b107-41d2-a373-e9cf202c9dfa_22,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('datatransformer', DataTransformer(enable_feature_sweeping=None, feature_sweeping_timeout=None,\n",
       "        is_onnx_compatible=None, logger=None, observer=None, task=None)), ('MaxAbsScaler', MaxAbsScaler(copy=True)), ('LightGBMClassifier', LightGBMClassifier(boosting_type='gbdt', class_weight=No... subsample=0.49526315789473685,\n",
       "          subsample_for_bin=200000, subsample_freq=0, verbose=-10))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = best_run[1]\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('datatransformer',\n",
       "   DataTransformer(enable_feature_sweeping=None, feature_sweeping_timeout=None,\n",
       "           is_onnx_compatible=None, logger=None, observer=None, task=None)),\n",
       "  ('MaxAbsScaler', MaxAbsScaler(copy=True)),\n",
       "  ('LightGBMClassifier',\n",
       "   LightGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "             colsample_bytree=0.2977777777777778, importance_type='split',\n",
       "             learning_rate=0.026323157894736843, max_bin=210, max_depth=6,\n",
       "             min_child_samples=3, min_child_weight=9, min_split_gain=1,\n",
       "             n_estimators=800, n_jobs=6, num_leaves=77, objective=None,\n",
       "             random_state=None, reg_alpha=0, reg_lambda=0.21052631578947367,\n",
       "             silent=True, subsample=0.49526315789473685,\n",
       "             subsample_for_bin=200000, subsample_freq=0, verbose=-10))],\n",
       " 'datatransformer': DataTransformer(enable_feature_sweeping=None, feature_sweeping_timeout=None,\n",
       "         is_onnx_compatible=None, logger=None, observer=None, task=None),\n",
       " 'MaxAbsScaler': MaxAbsScaler(copy=True),\n",
       " 'LightGBMClassifier': LightGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "           colsample_bytree=0.2977777777777778, importance_type='split',\n",
       "           learning_rate=0.026323157894736843, max_bin=210, max_depth=6,\n",
       "           min_child_samples=3, min_child_weight=9, min_split_gain=1,\n",
       "           n_estimators=800, n_jobs=6, num_leaves=77, objective=None,\n",
       "           random_state=None, reg_alpha=0, reg_lambda=0.21052631578947367,\n",
       "           silent=True, subsample=0.49526315789473685,\n",
       "           subsample_for_bin=200000, subsample_freq=0, verbose=-10),\n",
       " 'datatransformer__enable_feature_sweeping': None,\n",
       " 'datatransformer__feature_sweeping_timeout': None,\n",
       " 'datatransformer__is_onnx_compatible': None,\n",
       " 'datatransformer__logger': None,\n",
       " 'datatransformer__observer': None,\n",
       " 'datatransformer__task': None,\n",
       " 'MaxAbsScaler__copy': True,\n",
       " 'LightGBMClassifier__random_state': None,\n",
       " 'LightGBMClassifier__n_jobs': 6,\n",
       " 'LightGBMClassifier__boosting_type': 'gbdt',\n",
       " 'LightGBMClassifier__class_weight': None,\n",
       " 'LightGBMClassifier__colsample_bytree': 0.2977777777777778,\n",
       " 'LightGBMClassifier__importance_type': 'split',\n",
       " 'LightGBMClassifier__learning_rate': 0.026323157894736843,\n",
       " 'LightGBMClassifier__max_depth': 6,\n",
       " 'LightGBMClassifier__min_child_samples': 3,\n",
       " 'LightGBMClassifier__min_child_weight': 9,\n",
       " 'LightGBMClassifier__min_split_gain': 1,\n",
       " 'LightGBMClassifier__n_estimators': 800,\n",
       " 'LightGBMClassifier__num_leaves': 77,\n",
       " 'LightGBMClassifier__objective': None,\n",
       " 'LightGBMClassifier__reg_alpha': 0,\n",
       " 'LightGBMClassifier__reg_lambda': 0.21052631578947367,\n",
       " 'LightGBMClassifier__silent': True,\n",
       " 'LightGBMClassifier__subsample': 0.49526315789473685,\n",
       " 'LightGBMClassifier__subsample_for_bin': 200000,\n",
       " 'LightGBMClassifier__subsample_freq': 0,\n",
       " 'LightGBMClassifier__max_bin': 210,\n",
       " 'LightGBMClassifier__verbose': -10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text_x_HashOneHotEncode_8191',\n",
       " \"Text_y_CharGramCountVec_'innertext' works in ie, but not in firefox. i have some javascript code that works in ie containing the following:  however, it seems that the 'innertext' property does not work in firefox. is there some firefox equivalent? or is there a more generic, cross browser property that can be used?\",\n",
       " 'Text_y_CharGramCountVec_.prop() vs .attr(). so jquery 1.6 has the new function prop().  or in this case do they do the same thing? and if i do have to switch to using prop(), all the old attr() calls will break if i switch to 1.6? update see this fiddle: http://jsfiddle.net/maniator/jpuf2/ the console logs the getattribute as a string, and the attr as a string, but the prop as a cssstyledeclaration, why? and how does that affect my coding in the future?']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.named_steps['datatransformer'].get_engineered_feature_names()[-183:-180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model\n",
    "Read in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(data_path, \"balanced_pairs_test.tsv\")\n",
    "test = pd.read_csv(test_path, sep='\\t', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = (test.Text_x + ' ' + test.Text_y).values  # test[feature_columns]\n",
    "test_y = test[label_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['probabilities'] = best_run[1].predict_proba(test_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the testing data by dupe Id and question AnswerId.\n",
    "test.sort_values([group_column, answerid_column], inplace=True)\n",
    "\n",
    "# Extract the ordered probabilities.\n",
    "probabilities = (\n",
    "    test.probabilities\n",
    "    .groupby(test[group_column], sort=False)\n",
    "    .apply(lambda x: tuple(x.values)))\n",
    "\n",
    "# Get the individual records.\n",
    "output_columns_x = ['Id_x', 'AnswerId_x', 'Text_x']\n",
    "test_score = (test[output_columns_x]\n",
    "              .drop_duplicates()\n",
    "              .set_index(group_column))\n",
    "test_score['probabilities'] = probabilities\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.columns = ['Id', 'AnswerId', 'Text', 'probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score_rank(scores):\n",
    "    \"\"\"Compute the ranks of the scores.\"\"\"\n",
    "    return pd.Series(scores).rank(ascending=False)\n",
    "\n",
    "\n",
    "def label_index(label, label_order):\n",
    "    \"\"\"Compute the index of label in label_order.\"\"\"\n",
    "    loc = np.where(label == label_order)[0]\n",
    "    if loc.shape[0] == 0:\n",
    "        return None\n",
    "    return loc[0]\n",
    "\n",
    "\n",
    "def label_rank(label, scores, label_order):\n",
    "    \"\"\"Compute the rank of label using the scores.\"\"\"\n",
    "    loc = label_index(label, label_order)\n",
    "    if loc is None:\n",
    "        return len(scores) + 1\n",
    "    return score_rank(scores)[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model's performance.\n",
      "Accuracy @1 = 37.18%\n",
      "Accuracy @2 = 51.41%\n",
      "Accuracy @3 = 60.27%\n",
      "Mean Rank 7.3302\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model's performance.\")\n",
    "\n",
    "# Collect the ordered AnswerId for computing scores.\n",
    "labels = sorted(train[answerid_column].unique())\n",
    "label_order = pd.DataFrame({'label': labels})\n",
    "\n",
    "# Compute the ranks of the correct answers.\n",
    "test_score['Ranks'] = test_score.apply(lambda x:\n",
    "                                       label_rank(x.AnswerId,\n",
    "                                                  x.probabilities,\n",
    "                                                  label_order.label),\n",
    "                                       axis=1)\n",
    "\n",
    "# Compute the number of correctly ranked answers\n",
    "args_rank = 3\n",
    "for i in range(1, args_rank+1):\n",
    "    print('Accuracy @{} = {:.2%}'\n",
    "          .format(i, (test_score['Ranks'] <= i).mean()))\n",
    "mean_rank = test_score['Ranks'].mean()\n",
    "print('Mean Rank {:.4f}'.format(mean_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run120_path = os.path.join(\"outputs\", \"AutoML_ef96bf9d-54e7-4c0e-b365-b2f507ef80d9-120.pkl\")\n",
    "run120 = joblib.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
